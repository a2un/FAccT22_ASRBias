mutate(File = str_remove(File, "NO MEASURE"))%>%
mutate(File = as.factor(File))
saa_snr_flac <- read_tsv(paste0(data_path, "/Data/SpeechAccentArchive/LD/SNR_results_flac.txt"), col_names = c("File", "X", "Max_PR_signal","Max_Pr_noise", "SNR", "Noise_Int"))%>%
select(-c(X))%>%
mutate(Measure = str_extract(File, "NO MEASURE"))%>%
mutate(File = str_remove(File, "NO MEASURE"))%>%
mutate(File = as.factor(File))
saa_snr_flac <- read_tsv(paste0(data_path, "/Data/SpeechAccentArchive/SNR_results_flac.txt"), col_names = c("File", "X", "Max_PR_signal","Max_Pr_noise", "SNR", "Noise_Int"))%>%
select(-c(X))%>%
mutate(Measure = str_extract(File, "NO MEASURE"))%>%
mutate(File = str_remove(File, "NO MEASURE"))%>%
mutate(File = as.factor(File))
saa_snr_flac <- read_tsv(paste0(data_path, "/Data/SpeechAccentArchive/SNR_results_flac_saa.txt"), col_names = c("File", "X", "Max_PR_signal","Max_Pr_noise", "SNR", "Noise_Int"))%>%
select(-c(X))%>%
mutate(Measure = str_extract(File, "NO MEASURE"))%>%
mutate(File = str_remove(File, "NO MEASURE"))%>%
mutate(File = as.factor(File))
saa_stella_full <- left_join(saa_eval_demog, saa_snr_flac, by = "File")%>%
mutate(SNR_bin = case_when(SNR > 50 ~ "high",
TRUE ~ "low"))
saa_stella_lowsnr <- saa_stella_full %>%
filter(SNR < 50)
saa_snr_flac <- read_tsv(paste0(data_path, "/Data/SpeechAccentArchive/SNR_results_flac_saa.txt"), col_names = c("File", "X", "Max_PR_signal","Max_Pr_noise", "SNR", "Noise_Int"))%>%
select(-c(X))%>%
mutate(Measure = str_extract(File, "NO MEASURE"))%>%
mutate(File = str_remove(File, "NO MEASURE"))%>%
mutate(File = as.factor(File))
saa_snr_flac <- read_tsv(paste0(data_path, "/Data/SpeechAccentArchive/SNR_results_flac_saa.txt"), col_names = c("File", "X", "Max_PR_signal","Max_Pr_noise", "SNR", "Noise_Int"))%>%
select(-c(X))%>%
mutate(Measure = str_extract(File, "NO MEASURE"))%>%
mutate(File = str_remove(File, "NO MEASURE"))%>%
mutate(File = as.factor(File))
saa_stella_full <- left_join(saa_eval_demog, saa_snr_flac, by = "File")%>%
mutate(SNR_bin = case_when(SNR > 50 ~ "high",
TRUE ~ "low"))
View(saa_stella_full)
s <- saa_eval_demog%>%
mutate(File = paste0(str_to_lower(str_extract(File, "^\\w{3}")), str_extract(File, "\\d{1,3}")))%>%
mutate(number = str_extract(File, "\\d{1,3}"))%>%
rowwise()%>%
mutate(File = case_when(str_detect(number, "\\d{3}") ~ File,
str_detect(number, "^[0-9]{2}$") ~
gsub(number, paste0("0", as.character(number)),File),
str_detect(number, "[0-9]{1}$")   ~
gsub(number, paste0("00", as.character(number)),File)))
saa_stella_full <- left_join(s, saa_snr_flac, by = "File")%>%
mutate(SNR_bin = case_when(SNR > 50 ~ "high",
TRUE ~ "low"))
saa_stella_lowsnr <- saa_stella_full %>%
filter(SNR < 50)
saa_lowsnr <- saa_stella_full %>%
filter(SNR < 50)
facct_data_long <-
ivie_rea1%>%
mutate(corpus = "IViE",
UK_ROI = TRUE)%>%
rename(sex = Gender,
age = Age)%>%
bind_rows(saa_lowsnr)
facct_data_wide <-
ivie_rea1%>%
mutate(corpus = "IViE",
UK_ROI = TRUE)%>%
rename(sex = Gender,
age = Age)%>%
bind_rows(saa_lowsnr)%>%
pivot_wider(names_from = system, values_from = c(Sub, Ins, Del, WER))
facct_data_wide%>%
filter(corpus == "SAA")%>%
select(speakerid, variety, sex)%>%
distinct()%>%
tabyl(variety, sex)%>%
adorn_totals("col")%>%
adorn_percentages()%>%
adorn_pct_formatting(1)%>%
adorn_ns%>%
kable(col.names = c("Variety", "Female", "Male", "Total"))%>%
kable_minimal()
facct_data_wide%>%
filter(corpus == "SAA")%>%
group_by(variety)%>%
summarise(mean_age = mean(age))%>%
select(variety, mean_age)%>%
distinct()
ivie_rea1_wide%>%
select(variety, Gender)%>%
tabyl(variety, Gender)%>%
adorn_totals("col")%>%
adorn_percentages()%>%
adorn_pct_formatting(1)%>%
adorn_ns()%>%
kable(col.names = c("Variety", "Female", "Male", "Total"))%>%
kable_minimal()
facct_data_long%>%
filter(corpus == "SAA")%>%
select(-c(Ins, Sub, Del))%>%
spread(system, WER)%>%
group_by(native_language)%>%
summarise(mean_ama = round(mean(Amazon, na.rm = TRUE), digits = 2),
mean_google = round(mean(Google, na.rm = TRUE), digits = 2),
n= n())%>%
select(native_language,n, mean_ama, mean_google)%>%
kbl(col.names = c("L1", "n", "Amazon mean WER (%)", "Google mean WER (%)"))%>%
kable_minimal()
facct_data_long%>%
filter(corpus == "SAA")%>%
filter(native_language == "english" & country == "uk")%>%
select(-c(Ins, Sub, Del))%>%
spread(system, WER)%>%
group_by(variety)%>%
summarise(mean_ama = round(mean(Amazon, na.rm = TRUE), digits = 2),
mean_google = round(mean(Google, na.rm = TRUE), digits = 2),
n= n())%>%
select(variety,n, mean_ama, mean_google)%>%
kbl(col.names = c("L1", "n", "Amazon mean WER (%)", "Google mean WER (%)"))%>%
kable_minimal()
ivie_rea1_wide%>%
select(c(WER_Amazon, WER_Google, variety))%>%
group_by(variety)%>%
summarise(mean_ama = round(mean(WER_Amazon, na.rm = TRUE), digits = 2),
mean_google = round(mean(WER_Google, na.rm = TRUE), digits = 2),
n= n())%>%
select(variety,n, mean_ama, mean_google)%>%
distinct()%>%
kbl(col.names = c("Variety", "n", "Amazon mean WER (%)", "Google mean WER (%)"))%>%
kable_minimal()
saa_stella_speechrate <- read_tsv(paste0(data_path, "/Data/SpeechAccentArchive/saa_stella_speechrate.txt"))
ivie_rea1_speechrate <- read_tsv(paste0(data_path, "/Data/IViE/ivie_rea1_speechrate.txt"))
saa_stella_speechrate_sum <- saa_stella_speechrate%>%
group_by(File)%>%
summarise_all(funs(mean(.,)))
ivie_rea1_speechrate_sum <- ivie_rea1_speechrate%>%
group_by(File)%>%
summarise_all(funs(mean(.,)))%>%
mutate(Speaker = str_remove(as.character(File), "-rea1"))%>%
mutate(Speaker = str_remove(as.character(Speaker), "el|un|am|ee|ew|ub"))%>%
inner_join(ivie_rea1, by = "Speaker")%>%
distinct()%>%
select(-File.y)%>%
rename(File = File.x)
saa_stella <- right_join(saa_lowsnr, saa_stella_speechrate_sum)%>%
distinct()
saa_stella%>%
ggplot(aes(log(syllables_per_second), WER,color = system))+
geom_point()+
scale_fill_colorblind()
ivie_rea1_speechrate_sum%>%
ggplot(aes(log(syllables_per_second), WER,color = system))+
geom_point()+
scale_fill_colorblind()
ivie_rea1%>%
pivot_longer(cols = c(WER_Amazon, WER_Google), names_to = "System", values_to = "WER" )%>%
ggplot(aes(as.factor(Gender), WER))+
geom_boxplot()+
facet_grid(~System, scales = "free")
ivie_rea1%>%
ggplot(aes(as.factor(Gender), WER))+
geom_boxplot()+
facet_grid(~System, scales = "free")
ivie_rea1%>%
ggplot(aes(as.factor(Gender), WER))+
geom_boxplot()+
facet_grid(~system, scales = "free")
saa_lowsnr%>%
ggplot(aes(as.factor(Gender), WER))+
geom_boxplot()+
facet_grid(~system, scales = "free")
saa_lowsnr%>%
ggplot(aes(as.factor(sex), WER))+
geom_boxplot()+
facet_grid(~system, scales = "free")
facct_data%>%
filter(system == "Amazon")%>%
ggplot(aes(as.factor(sex), WER))+
geom_boxplot()+
facet_grid(~corpus, scales = "free")
saa_eval_demog <- saa_eval %>%
rename(filename = File)%>%
inner_join(saa_demog, by = "filename")%>%
select(-c(X, X.1, X.2, file_missing.))%>%
mutate(Speaker = paste0("SAA", filename))%>%
rename(File = filename)%>%
mutate(corpus = "SAA",
UK_ROI = if_else(country %in% c("uk", "ireland") & native_language == "english", TRUE, FALSE))
s <- saa_eval_demog%>%
mutate(File = paste0(str_to_lower(str_extract(File, "^\\w{3}")), str_extract(File, "\\d{1,3}")))%>%
mutate(number = str_extract(File, "\\d{1,3}"))%>%
rowwise()%>%
mutate(File = case_when(str_detect(number, "\\d{3}") ~ File,
str_detect(number, "^[0-9]{2}$") ~
gsub(number, paste0("0", as.character(number)),File),
str_detect(number, "[0-9]{1}$")   ~
gsub(number, paste0("00", as.character(number)),File)))
saa_stella_full <- left_join(s, saa_snr_flac, by = "File")%>%
mutate(SNR_bin = case_when(SNR > 50 ~ "high",
TRUE ~ "low"))
saa_lowsnr <- saa_stella_full %>%
filter(SNR < 50)
facct_data%>%
filter(system == "Amazon")%>%
ggplot(aes(as.factor(sex), WER))+
geom_boxplot()+
facet_grid(~corpus, scales = "free")
facct_data_long%>%
filter(system == "Amazon")%>%
ggplot(aes(as.factor(sex), WER))+
geom_boxplot()+
facet_grid(~corpus, scales = "free")
saa_lowsnr%>%
ggplot(aes(age, WER, color = system))+
geom_point()
saa_lowsnr%>%
mutate(L1_english = if_else(str_detect(native_language, "english"),"L1 English","L2 English"))%>%
ggplot(aes(as.factor(L1_english), WER, fill = L1_english))+
geom_boxplot()+
geom_jitter(alpha = 0.3) +
facet_grid(~system)+
scale_fill_manual(values = c("#56B4E9", "#E69F00"))+
theme_minimal()+
theme(legend.position = "none",
axis.title.x = element_blank()) +
ggtitle("Word Error Rate (WER): Speech Accent Archive")
ggsave("WER_SAA_L1L2.eps")
ivie_rea1%>%
mutate(bilingual = case_when(variety %in% c("Bradford Punjabi", "Cardiff Welsh", "London West Indian") ~ TRUE,
TRUE ~ FALSE))%>%
pivot_longer(cols = c(WER_Amazon, WER_Google), names_to = "System", values_to = "WER" )%>%
ggplot(aes(bilingual, WER))+
geom_boxplot()+
facet_grid(~System)+
scale_x_discrete(guide = guide_axis(n.dodge=2))
ivie_rea1_long%>%
mutate(bilingual = case_when(variety %in% c("Bradford Punjabi", "Cardiff Welsh", "London West Indian") ~ TRUE,
TRUE ~ FALSE))%>%
ggplot(aes(bilingual, WER))+
geom_boxplot()+
facet_grid(~System)+
scale_x_discrete(guide = guide_axis(n.dodge=2))
ivie_rea1%>%
mutate(bilingual = case_when(variety %in% c("Bradford Punjabi", "Cardiff Welsh", "London West Indian") ~ TRUE,
TRUE ~ FALSE))%>%
ggplot(aes(bilingual, WER))+
geom_boxplot()+
facet_grid(~system)+
scale_x_discrete(guide = guide_axis(n.dodge=2))
saa_lowsnr%>%
filter(system == "Amazon")%>%
filter(native_language == "english" & country == "uk")%>%
mutate(stat_sig = case_when(variety %in% c("NorthernIrish", "North") & system == "Amazon" ~1,
variety == "South" ~ 2,
TRUE ~ 3))%>%
ggplot(aes(reorder(variety, WER), WER, fill =as.factor(stat_sig)))+
geom_boxplot()+
scale_fill_manual(breaks = c(1, 2), values = c("#CC79A7", "#009E73", "#FFFFFF"))+
#theme_minimal()+
ylim(0, 100)+
#facet_wrap(~system)+
theme(legend.position = "none")+
theme(strip.background = element_rect(fill="#56B4E9"))+
theme(axis.title.x=element_blank())+
ggtitle("WER: Amazon on SAA")
saa_stella_lowsnr_ama <- saa_lowsnr%>%
filter(system == "Amazon")%>%
mutate(L1_english = if_else(str_detect(native_language, "english"),"L1 English","L2 English"))%>%
mutate(SPS_z = scale(as.numeric(syllables_per_second)))%>%
mutate(age_z = scale(age))%>%
mutate(years_onset = age - age_onset)%>%
mutate(yrs_onset_z = scale(years_onset))
saa_stella <- right_join(saa_lowsnr, saa_stella_speechrate_sum)%>%
distinct()
saa_stella_lowsnr_ama <- saa_stella%>%
filter(system == "Amazon")%>%
mutate(L1_english = if_else(str_detect(native_language, "english"),"L1 English","L2 English"))%>%
mutate(SPS_z = scale(as.numeric(syllables_per_second)))%>%
mutate(age_z = scale(age))%>%
mutate(years_onset = age - age_onset)%>%
mutate(yrs_onset_z = scale(years_onset))
saa_stella_lowsnr_ama <- saa_stella%>%
filter(system == "Amazon")%>%
mutate(L1_english = if_else(str_detect(native_language, "english"),"L1 English","L2 English"))
saa_stella_lowsnr_ama%>%
ggplot(aes(WER))+
geom_density()
saa_stella_lowsnr_ama%>%
ggplot(aes(WER, color = L1_english))+
geom_density()
saa_stella_lowsnr_ama$sex <- factor(saa_stella_lowsnr_ama$sex, levels = c("male", "female"))
contrasts(saa_stella_lowsnr_ama$sex) <- c(-0.5,0.5)
saa_stella_lowsnr_ama$L1_english <- factor(saa_stella_lowsnr_ama$L1_english, levels = c("L1 English", "L2 English"))
contrasts(saa_stella_lowsnr_ama$L1_english) <- c(-0.5,0.5)
saa_stella_lowsnr_ama$SPS_z <-scale(saa_stella_lowsnr_ama$syllables_per_second)
saa_stella_lowsnr_ama$age_z <-scale(saa_stella_lowsnr_ama$age)
saa_ama_lm1 <- lm(WER ~ L1_english + sex  + SPS_z + age_z, data = saa_stella_lowsnr_ama)
saa_ama_lm1_inter <- lm(WER ~ L1_english*sex  + SPS_z + age_z, data = saa_stella_lowsnr_ama)
saa_ama_lm1%>%
stargazer::stargazer()
saa_stella_lowsnr_google <- saa_stella_lowsnr%>%
filter(system == "Google")%>%
mutate(L1_english = if_else(str_detect(native_language, "english"),"L1 English","L2 English"))
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool", "London West Indian", "Newcastle", "Belfast", "Dublin"))
ivie_rea1_speechrate_sum$Gender <- factor(ivie_rea1_speechrate_sum$Gender, levels = c("m", "f"))
contrasts(ivie_rea1_speechrate_sum$Gender) <- c(-0.5,0.5)
ivie_rea1_speechrate_sum$SPS_z <-scale(ivie_rea1_speechrate_sum$syllables_per_second)
ivie_ama_lm1 <- lm(WER_Amazon ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
ivie_rea1_speechrate_sum <- ivie_rea1_speechrate_wide%>%
group_by(File)%>%
summarise_all(funs(mean(.,)))%>%
mutate(Speaker = str_remove(as.character(File), "-rea1"))%>%
mutate(Speaker = str_remove(as.character(Speaker), "el|un|am|ee|ew|ub"))%>%
inner_join(ivie_rea1, by = "Speaker")%>%
distinct()%>%
select(-File.y)%>%
rename(File = File.x)
ivie_rea1_speechrate_sum <- ivie_rea1_speechrate%>%
group_by(File)%>%
summarise_all(funs(mean(.,)))%>%
mutate(Speaker = str_remove(as.character(File), "-rea1"))%>%
mutate(Speaker = str_remove(as.character(Speaker), "el|un|am|ee|ew|ub"))%>%
inner_join(ivie_rea1_wide, by = "Speaker")%>%
distinct()%>%
select(-File.y)%>%
rename(File = File.x)
ivie_rea1_speechrate_sum%>%
ggplot(aes(log(syllables_per_second), WER,color = system))+
geom_point()+
scale_fill_colorblind()
saa_stella%>%
ggplot(aes(log(syllables_per_second), WER,color = system))+
geom_point()+
scale_fill_colorblind()
ivie_rea1_speechrate_sum%>%
pivot_longer(cols = c(WER_Amazon, WER_Google), names_to = "System", values_to = "WER" )%>%
ggplot(aes(log(syllables_per_second), WER,color = system))+
geom_point()+
scale_fill_colorblind()
ivie_rea1_speechrate_sum%>%
pivot_longer(cols = c(WER_Amazon, WER_Google), names_to = "System", values_to = "WER" )%>%
ggplot(aes(log(syllables_per_second), WER,color = System))+
geom_point()+
scale_fill_colorblind()
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool", "London West Indian", "Newcastle", "Belfast", "Dublin"))
ivie_rea1_speechrate_sum$Gender <- factor(ivie_rea1_speechrate_sum$Gender, levels = c("m", "f"))
contrasts(ivie_rea1_speechrate_sum$Gender) <- c(-0.5,0.5)
ivie_rea1_speechrate_sum$SPS_z <-scale(ivie_rea1_speechrate_sum$syllables_per_second)
ivie_ama_lm1 <- lm(WER_Amazon ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_ama_lm1)
ivie_ama_lm1_inter <- lm(WER_Amazon ~ variety* Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_ama_lm1_inter)
ivie_ama_lm1_inter <- lm(WER_Amazon ~ variety* Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_ama_lm1_inter)
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("London West Indian", "Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool" , "Newcastle", "Belfast", "Dublin"))
ivie_google_lm2 <- lm(WER_Google ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_google_lm2)
ivie_google_lm2_inter <- lm(WER_Google ~ variety * Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_google_lm2_inter)
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("London West Indian", "Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool" , "Newcastle", "Belfast", "Dublin"))
ivie_google_lm2 <- lm(WER_Google ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_google_lm2)
ivie_google_lm2_inter <- lm(WER_Google ~ variety * Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_google_lm2_inter)
anova(ivie_google_lm2, ivie_google_lm2_inter)
summ(ivie_ama_lm1_inter)
ivie_google_lm1 <- lm(WER_Google ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_google_lm2)
summ(ivie_google_lm2_inter)
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool", "London West Indian", "Newcastle", "Belfast", "Dublin"))
ivie_rea1_speechrate_sum$Gender <- factor(ivie_rea1_speechrate_sum$Gender, levels = c("m", "f"))
contrasts(ivie_rea1_speechrate_sum$Gender) <- c(-0.5,0.5)
ivie_rea1_speechrate_sum$Gender <- factor(ivie_rea1_speechrate_sum$Gender, levels = c("m", "f"))
contrasts(ivie_rea1_speechrate_sum$Gender) <- c(-0.5,0.5)
ivie_rea1_speechrate_sum$SPS_z <-scale(ivie_rea1_speechrate_sum$syllables_per_second)
ivie_ama_lm1 <- lm(WER_Amazon ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_ama_lm1)
ivie_ama_lm1_inter <- lm(WER_Amazon ~ variety* Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_ama_lm1_inter)
anova(ivie_ama_lm1, ivie_ama_lm1_inter)
summ(ivie_ama_lm1)
summ(ivie_ama_lm1)
summ(ivie_ama_lm1)
summ(ivie_ama_lm1)
library(bookdown)
library(tidyverse)
library(readr)
library(ggplot2)
library(jtools)
library(svglite)
library(stringr)
library(stringi)
library(readr)
library(janitor)
library(ggpubr)
library(kableExtra)
library(tidylog)
library(lme4)
summ(ivie_ama_lm1)
summ(ivie_ama_lm1)
summ(ivie_google_lm2)
knitr::opts_chunk$set( warning = FALSE, error = FALSE, message = FALSE, cache = TRUE)
library(bookdown)
library(tidyverse)
library(readr)
library(ggplot2)
library(jtools)
library(svglite)
library(stringr)
library(stringi)
library(readr)
library(janitor)
library(ggpubr)
library(kableExtra)
library(ggthemes)
library(tidylog)
saa_demog <- read.csv(paste0(data_path, "/Data/SpeechAccentArchive/speakers_all.csv"))%>%
mutate(variety = case_when(str_detect(birthplace, "[Ss]cotland") ~ "Scottish",
str_detect(birthplace, "Southern|South|SW|SE|[Ss]urrey|[Oo]xford|[Ll]ondon|
|[Ww]indsor|[Ww]ight|[Ll]ittlehampton|[Bb]uckinghamshire|
|leighton buzzard|exminister|southhampton|[Hh]ertfordshire|bury|
|middlesex|bournesmouth")
~ "South",
str_detect(birthplace, "[Ww]ales") ~ "Welsh",
str_detect(birthplace, "[Nn]orthern ireland")  ~ "NorthernIrish",
str_detect(birthplace, "[Mm]anchester|[Ll]eeds|[Dd]erby|[Dd]udley|
|rutland|[Bb]irmingham|[Nn]ewcastle|
|lancashire|leicester|grimsby|chester|[Yy]ork|[Bb]irkenhead|[Nn]orfolk|
|[Nn]ottingham|[Ss]tafford|[Ww]arwick|Cumbria|avon|donington") ~ "North",
str_detect(country, "[Ii]reland") ~ "Irish",
TRUE ~ as.character(native_language))) # add variety
data_path <- "C:/Users/ninal/UoE_OneDrive/University/Postgrad/Research/Research_Projects/ASR_Bias/FAccT_data"
saa_demog <- read.csv(paste0(data_path, "/Data/SpeechAccentArchive/speakers_all.csv"))%>%
mutate(variety = case_when(str_detect(birthplace, "[Ss]cotland") ~ "Scottish",
str_detect(birthplace, "Southern|South|SW|SE|[Ss]urrey|[Oo]xford|[Ll]ondon|
|[Ww]indsor|[Ww]ight|[Ll]ittlehampton|[Bb]uckinghamshire|
|leighton buzzard|exminister|southhampton|[Hh]ertfordshire|bury|
|middlesex|bournesmouth")
~ "South",
str_detect(birthplace, "[Ww]ales") ~ "Welsh",
str_detect(birthplace, "[Nn]orthern ireland")  ~ "NorthernIrish",
str_detect(birthplace, "[Mm]anchester|[Ll]eeds|[Dd]erby|[Dd]udley|
|rutland|[Bb]irmingham|[Nn]ewcastle|
|lancashire|leicester|grimsby|chester|[Yy]ork|[Bb]irkenhead|[Nn]orfolk|
|[Nn]ottingham|[Ss]tafford|[Ww]arwick|Cumbria|avon|donington") ~ "North",
str_detect(country, "[Ii]reland") ~ "Irish",
TRUE ~ as.character(native_language))) # add variety
files <- list.files(paste0(data_path, "/Data/SpeechAccentArchive/sclite_output/google"), "wer_summary.csv", recursive = TRUE)%>%
as.data.frame()
colnames(files)[1] = "Files"
filenames <- files %>%
mutate(path = paste0(data_path, "/Data/SpeechAccentArchive/sclite_output/google/", Files))%>%
separate(Files, into = c("folder", "file"), sep = "/")
google_eval <-  map_df(filenames$path, read_csv)%>%
mutate(system = "Google",
lng_model = 'en-GB')%>%
distinct()
ivie_rea1_google <- read_csv(paste0(data_path, "/Data/IViE/error_analysis/wer_summary_google.csv"))%>%
mutate(Speaker = str_remove(as.character(File), "-rea1"))%>%
mutate(Gender = str_extract(as.character(File), "f|m"))%>%
mutate(Age = 16)%>% # speakers are about 16 years old, all recorded in school
mutate(variety = case_when(str_detect(Speaker, 'p') ~ "Bradford Punjabi",
str_detect(Speaker, 'car') ~ "Cardiff Welsh",
str_detect(Speaker, 'b') ~ "Belfast",
str_detect(Speaker, 'c') ~ "Cambridge",
str_detect(Speaker, 'p') ~ "Bradford Punjabi",
str_detect(Speaker, 'liv') ~ "Liverpool",
str_detect(Speaker, 'l') ~ "Leeds",
str_detect(Speaker, 'n') ~ "Newcastle",
str_detect(Speaker, 'j') ~ "London West Indian",
str_detect(Speaker, 'd') ~ "Dublin"))%>%
mutate(system = "Google")%>%
mutate(lng_model = "en-GB")
ivie_rea1_amazon <- read_csv(paste0(data_path, "/Data/IViE/error_analysis/wer_summary_amazon.csv"))%>%
mutate(Speaker = str_remove(as.character(File), "-rea1"))%>%
mutate(Gender = str_extract(as.character(File), "f|m"))%>%
mutate(Age = 16)%>% # speakers are about 16 years old, all recorded in school
mutate(variety = case_when(str_detect(Speaker, 'p') ~ "Bradford Punjabi",
str_detect(Speaker, 'car') ~ "Cardiff Welsh",
str_detect(Speaker, 'b') ~ "Belfast",
str_detect(Speaker, 'c') ~ "Cambridge",
str_detect(Speaker, 'p') ~ "Bradford Punjabi",
str_detect(Speaker, 'liv') ~ "Liverpool",
str_detect(Speaker, 'l') ~ "Leeds",
str_detect(Speaker, 'n') ~ "Newcastle",
str_detect(Speaker, 'j') ~ "London West Indian",
str_detect(Speaker, 'd') ~ "Dublin"))%>%
mutate(system = "Amazon")%>%
mutate(lng_model = "en-GB")
View(ivie_rea1_amazon)
ivie_rea1_wide <- bind_rows(ivie_rea1_amazon, ivie_rea1_google)%>%
pivot_wider(names_from = system, values_from = c(Sub, Ins, Del, WER))
ivie_rea1 <- bind_rows(ivie_rea1_amazon, ivie_rea1_google)
ivie_rea1_speechrate <- read_tsv(paste0(data_path, "/Data/IViE/ivie_rea1_speechrate.txt"))
ivie_rea1_speechrate_sum <- ivie_rea1_speechrate%>%
group_by(File)%>%
summarise_all(funs(mean(.,)))%>%
mutate(Speaker = str_remove(as.character(File), "-rea1"))%>%
mutate(Speaker = str_remove(as.character(Speaker), "el|un|am|ee|ew|ub"))%>%
inner_join(ivie_rea1_wide, by = "Speaker")%>%
distinct()%>%
select(-File.y)%>%
rename(File = File.x)
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool", "London West Indian", "Newcastle", "Belfast", "Dublin"))
View(ivie_rea1_speechrate_sum)
ivie_rea1_speechrate_sum$Gender <- factor(ivie_rea1_speechrate_sum$Gender, levels = c("m", "f"))
contrasts(ivie_rea1_speechrate_sum$Gender) <- c(-0.5,0.5)
ivie_rea1_speechrate_sum$SPS_z <-scale(ivie_rea1_speechrate_sum$syllables_per_second)
ivie_ama_lm1 <- lm(WER_Amazon ~ variety + Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_ama_lm1)
ivie_rea1_speechrate_sum$variety <- factor(ivie_rea1_speechrate_sum$variety, levels = c("London West Indian", "Cambridge", "Cardiff Welsh", "Bradford Punjabi", "Leeds", "Liverpool" , "Newcastle", "Belfast", "Dublin"))
summ(ivie_google_lm2_inter)
ivie_google_lm2_inter <- lm(WER_Google ~ variety * Gender  + SPS_z, data = ivie_rea1_speechrate_sum)
summ(ivie_google_lm2_inter)
summ(saa_ama_lm1)
saa_ama_lm1 <- lm(WER ~ L1_english + sex  + SPS_z + age_z, data = saa_stella_lowsnr_ama)
